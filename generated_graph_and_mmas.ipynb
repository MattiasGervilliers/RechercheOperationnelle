{
 "cells": [
  {
   "cell_type": "code",
   "id": "de8a730d-c3e0-4989-823c-2319f6d3dfdb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import math\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def is_connected(enriched):\n",
    "    G = nx.Graph()\n",
    "    for node_id, attrs in enriched.items():\n",
    "        G.add_node(node_id)\n",
    "        for neighbor_id in attrs['neighbours']:\n",
    "            G.add_edge(node_id, neighbor_id)\n",
    "    return nx.is_connected(G), G\n",
    "\n",
    "\n",
    "def build_logical_graph_data(\n",
    "        data,\n",
    "        p_hub=0.6,\n",
    "        hub_dist_thresh=10,\n",
    "        k_villages=2,\n",
    "        max_village_dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Enrichit `data` en lui attribuant des IDs entiers pour hubs et sous‑villes,\n",
    "    et construit pour chaque nœud :\n",
    "      - 'cluster'    : ID du hub d'origine\n",
    "      - 'neighbours' : dict {voisin_id: [poids,...], ...}\n",
    "    \"\"\"\n",
    "    enriched = {}\n",
    "    vid_map = {}  # map (hub_id, sv_id) → new int ID\n",
    "    next_vid = 0\n",
    "\n",
    "    # 1) Assignation des IDs et initialisation des hubs\n",
    "    for hub_id, hub in data.items():\n",
    "        vid_map[(hub_id, None)] = next_vid\n",
    "        enriched[next_vid] = {\n",
    "            'x': hub['x'], 'y': hub['y'],\n",
    "            'cluster': next_vid,\n",
    "            'neighbours': {},\n",
    "            'distance': 99999\n",
    "        }\n",
    "        next_vid += 1\n",
    "\n",
    "    # 2) Assignation des IDs et initialisation des sous‑villes\n",
    "    for hub_id, hub in data.items():\n",
    "        hub_vid = vid_map[(hub_id, None)]\n",
    "        for sv_id, coord in hub.get('sousVilles', {}).items():\n",
    "            vid_map[(hub_id, sv_id)] = next_vid\n",
    "            enriched[next_vid] = {\n",
    "                'x': coord['x'], 'y': coord['y'],\n",
    "                'cluster': hub_vid,\n",
    "                'neighbours': {},\n",
    "                'distance': 99999\n",
    "            }\n",
    "            next_vid += 1\n",
    "\n",
    "    degres_max_hub = 4\n",
    "    # 3) Connexions hub–hub\n",
    "    hubs = [v for (h, sv), v in vid_map.items() if sv is None]\n",
    "    for i in range(len(hubs)):\n",
    "        for j in range(i + 1, len(hubs)):\n",
    "            a, b = hubs[i], hubs[j]\n",
    "            xa, ya = enriched[a]['x'], enriched[a]['y']\n",
    "            xb, yb = enriched[b]['x'], enriched[b]['y']\n",
    "            dist = math.hypot(xa - xb, ya - yb)\n",
    "\n",
    "            da = len(enriched[a]['neighbours'])\n",
    "            db = len(enriched[b]['neighbours'])\n",
    "            if dist < hub_dist_thresh and random.random() < p_hub:\n",
    "                if da < degres_max_hub and db < degres_max_hub:\n",
    "                    enriched[a]['neighbours'].setdefault(b, []).append(dist)\n",
    "                    enriched[b]['neighbours'].setdefault(a, []).append(dist)\n",
    "\n",
    "    degres_max_vil = 3\n",
    "    # 4) Connexion sous-ville ↔ hub parent\n",
    "    for hub_id, hub in data.items():\n",
    "        # on récupère l’ID numérique du hub dans enriched\n",
    "        hub_vid = vid_map[(hub_id, None)]\n",
    "        xa, ya = enriched[hub_vid]['x'], enriched[hub_vid]['y']\n",
    "\n",
    "        # on collecte d’abord les distances hub→sous-villes\n",
    "        dists = []\n",
    "        for sv_id, coord in hub.get('sousVilles', {}).items():\n",
    "            # on récupère l’ID numérique de la sous-ville\n",
    "            vid = vid_map[(hub_id, sv_id)]\n",
    "            xb, yb = coord['x'], coord['y']\n",
    "            d = math.hypot(xa - xb, ya - yb)\n",
    "            dists.append((d, vid))\n",
    "\n",
    "        # tri par distance croissante\n",
    "        dists.sort(key=lambda t: t[0])\n",
    "\n",
    "        # on connecte TOUTES les sous-villes dont la distance ≤ max_village_dist (si défini)\n",
    "        for dist, vid in dists:\n",
    "            if max_village_dist is not None and dist > max_village_dist:\n",
    "                continue\n",
    "            enriched[hub_vid]['neighbours'].setdefault(vid, []).append(dist)\n",
    "            enriched[vid]['neighbours'].setdefault(hub_vid, []).append(dist)\n",
    "\n",
    "    # 5) Connexion sous‑ville ↔ sous‑ville\n",
    "    villages = [v for (h, sv), v in vid_map.items() if sv is not None]\n",
    "    for v in villages:\n",
    "        xv, yv = enriched[v]['x'], enriched[v]['y']\n",
    "        # calculer distances aux autres sous‑villes\n",
    "        dists = []\n",
    "        for u in villages:\n",
    "            if u == v: continue\n",
    "            xu, yu = enriched[u]['x'], enriched[u]['y']\n",
    "            dist = math.hypot(xv - xu, yv - yu)\n",
    "            if max_village_dist is not None and dist > max_village_dist:\n",
    "                continue\n",
    "            if len(enriched[v]['neighbours']) >= degres_max_vil:\n",
    "                break\n",
    "            if len(enriched[u]['neighbours']) >= degres_max_vil:\n",
    "                continue\n",
    "            dists.append((dist, u))\n",
    "        # relier aux k plus proches\n",
    "        dists.sort(key=lambda t: t[0])\n",
    "        for dist, u in dists[:k_villages]:\n",
    "            enriched[v]['neighbours'].setdefault(u, []).append(dist)\n",
    "            enriched[u]['neighbours'].setdefault(v, []).append(dist)\n",
    "\n",
    "    # 6) Assurer la connexité\n",
    "    G = nx.Graph()\n",
    "    for vid, attrs in enriched.items():\n",
    "        G.add_node(vid)\n",
    "        for neigh, w in attrs['neighbours'].items():\n",
    "            G.add_edge(vid, neigh)\n",
    "    if not nx.is_connected(G):\n",
    "        comps = list(nx.connected_components(G))\n",
    "        for c1, c2 in zip(comps, comps[1:]):\n",
    "            best = (None, None, float('inf'))\n",
    "            for a in c1:\n",
    "                for b in c2:\n",
    "                    dx = enriched[a]['x'] - enriched[b]['x']\n",
    "                    dy = enriched[a]['y'] - enriched[b]['y']\n",
    "                    d = math.hypot(dx, dy)\n",
    "                    if d < best[2]:\n",
    "                        best = (a, b, d)\n",
    "            a, b, d = best\n",
    "            enriched[a]['neighbours'].setdefault(b, []).append(d)\n",
    "            enriched[b]['neighbours'].setdefault(a, []).append(d)\n",
    "\n",
    "    return enriched\n",
    "\n",
    "\n",
    "def define_cities_regions(data, MIN_X, MAX_X, MIN_Y, MAX_Y, max_iters=10):\n",
    "    \"\"\"\n",
    "    Étend chaque point pour définir sa « boîte » périphérique\n",
    "    [x1,x2]×[y1,y2], sans empiéter sur ses voisins,\n",
    "    et limitée à ±(cadre/10) autour du centre.\n",
    "    \"\"\"\n",
    "    # extension max = 1/10 du cadre\n",
    "    ext_x = (MAX_X - MIN_X) / 10\n",
    "    ext_y = (MAX_Y - MIN_Y) / 10\n",
    "\n",
    "    # 1) On démarre : chaque ville peut potentiellement occuper tout l'espace\n",
    "    for i in data:\n",
    "        data[i]['periph'] = {\n",
    "            'x1': MIN_X, 'x2': MAX_X,\n",
    "            'y1': MIN_Y, 'y2': MAX_Y\n",
    "        }\n",
    "\n",
    "    # 2) Ajustements itératifs\n",
    "    for _ in range(max_iters):\n",
    "        changed = False\n",
    "\n",
    "        # --- Phase X ---\n",
    "        for i, pt in data.items():\n",
    "            x_i, y1_i, y2_i = pt['x'], pt['periph']['y1'], pt['periph']['y2']\n",
    "            lefts, rights = [], []\n",
    "\n",
    "            for j, other in data.items():\n",
    "                if j == i: continue\n",
    "                # ignore si bandes Y disjointes\n",
    "                if other['periph']['y2'] < y1_i or other['periph']['y1'] > y2_i:\n",
    "                    continue\n",
    "                midpoint = (x_i + other['x']) / 2\n",
    "                (lefts if other['x'] < x_i else rights).append(midpoint)\n",
    "\n",
    "            x1_new = max(lefts) if lefts else MIN_X\n",
    "            x2_new = min(rights) if rights else MAX_X\n",
    "\n",
    "            # clamp autour de x_i\n",
    "            x1_new = max(x1_new, x_i - ext_x)\n",
    "            x2_new = min(x2_new, x_i + ext_x)\n",
    "\n",
    "            old = pt['periph']\n",
    "            if x1_new != old['x1'] or x2_new != old['x2']:\n",
    "                changed = True\n",
    "            old['x1'], old['x2'] = x1_new, x2_new\n",
    "\n",
    "        # --- Phase Y ---\n",
    "        for i, pt in data.items():\n",
    "            y_i, x1_i, x2_i = pt['y'], pt['periph']['x1'], pt['periph']['x2']\n",
    "            lowers, uppers = [], []\n",
    "\n",
    "            for j, other in data.items():\n",
    "                if j == i: continue\n",
    "                # ignore si bandes X disjointes\n",
    "                if other['periph']['x2'] < x1_i or other['periph']['x1'] > x2_i:\n",
    "                    continue\n",
    "                midpoint = (y_i + other['y']) / 2\n",
    "                (lowers if other['y'] < y_i else uppers).append(midpoint)\n",
    "\n",
    "            y1_new = max(lowers) if lowers else MIN_Y\n",
    "            y2_new = min(uppers) if uppers else MAX_Y\n",
    "\n",
    "            # clamp autour de y_i\n",
    "            y1_new = max(y1_new, y_i - ext_y)\n",
    "            y2_new = min(y2_new, y_i + ext_y)\n",
    "\n",
    "            old = pt['periph']\n",
    "            if y1_new != old['y1'] or y2_new != old['y2']:\n",
    "                changed = True\n",
    "            old['y1'], old['y2'] = y1_new, y2_new\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    data = expand_cities_regions(data, MIN_X, MAX_X, MIN_Y, MAX_Y)\n",
    "    return data\n",
    "\n",
    "\n",
    "def expand_cities_regions(data, MIN_X, MAX_X, MIN_Y, MAX_Y):\n",
    "    \"\"\"\n",
    "    Pour chaque hub, agrandit sa boîte periph de ±2 unités autour\n",
    "    du centre, sans empiéter sur les voisins :\n",
    "      - à GAUCHE : on calcule x1 = max(MAX x2 des bloqueurs, MIN_X, cx - 2)\n",
    "      - à DROITE: x2 = min(MIN x1 des bloqueurs, MAX_X, cx + 2)\n",
    "      - en BAS   : y1 = max(MAX y2 des bloqueurs, MIN_Y, cy - 2)\n",
    "      - en HAUT  : y2 = min(MIN y1 des bloqueurs, MAX_Y, cy + 2)\n",
    "    \"\"\"\n",
    "    ext_x = (MAX_X - MIN_X) / 5.0\n",
    "    ext_y = (MAX_Y - MIN_Y) / 5.0\n",
    "\n",
    "    for i, hub in data.items():\n",
    "        xi, yi = hub['x'], hub['y']\n",
    "\n",
    "        # --- gauche ---\n",
    "        cand = MIN_X\n",
    "        # plafond d’extension\n",
    "        left_ext = xi - ext_x\n",
    "        cand = max(cand, left_ext)\n",
    "        # mi-distance au plus proche voisin à gauche\n",
    "        mids = []\n",
    "        for j, other in data.items():\n",
    "            if j == i: continue\n",
    "            y1, y2 = hub['periph']['y1'], hub['periph']['y2']\n",
    "            oy1, oy2 = other['periph']['y1'], other['periph']['y2']\n",
    "            # vrai chevauchement Y ?\n",
    "            if min(y2, oy2) > max(y1, oy1) and other['x'] < xi:\n",
    "                mids.append((xi + other['x']) / 2)\n",
    "        if mids:\n",
    "            cand = max(cand, max(mids))\n",
    "        hub['periph']['x1'] = cand\n",
    "\n",
    "        # --- droite ---\n",
    "        cand = MAX_X\n",
    "        right_ext = xi + ext_x\n",
    "        cand = min(cand, right_ext)\n",
    "        mids = []\n",
    "        for j, other in data.items():\n",
    "            if j == i: continue\n",
    "            y1, y2 = hub['periph']['y1'], hub['periph']['y2']\n",
    "            oy1, oy2 = other['periph']['y1'], other['periph']['y2']\n",
    "            if min(y2, oy2) > max(y1, oy1) and other['x'] > xi:\n",
    "                mids.append((xi + other['x']) / 2)\n",
    "        if mids:\n",
    "            cand = min(cand, min(mids))\n",
    "        hub['periph']['x2'] = cand\n",
    "\n",
    "        # --- bas ---\n",
    "        cand = MIN_Y\n",
    "        bot_ext = yi - ext_y\n",
    "        cand = max(cand, bot_ext)\n",
    "        mids = []\n",
    "        for j, other in data.items():\n",
    "            if j == i: continue\n",
    "            x1, x2 = hub['periph']['x1'], hub['periph']['x2']\n",
    "            ox1, ox2 = other['periph']['x1'], other['periph']['x2']\n",
    "            if min(x2, ox2) > max(x1, ox1) and other['y'] < yi:\n",
    "                mids.append((yi + other['y']) / 2)\n",
    "        if mids:\n",
    "            cand = max(cand, max(mids))\n",
    "        hub['periph']['y1'] = cand\n",
    "\n",
    "        # --- haut ---\n",
    "        cand = MAX_Y\n",
    "        top_ext = yi + ext_y\n",
    "        cand = min(cand, top_ext)\n",
    "        mids = []\n",
    "        for j, other in data.items():\n",
    "            if j == i: continue\n",
    "            x1, x2 = hub['periph']['x1'], hub['periph']['x2']\n",
    "            ox1, ox2 = other['periph']['x1'], other['periph']['x2']\n",
    "            if min(x2, ox2) > max(x1, ox1) and other['y'] > yi:\n",
    "                mids.append((yi + other['y']) / 2)\n",
    "        if mids:\n",
    "            cand = min(cand, min(mids))\n",
    "        hub['periph']['y2'] = cand\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def display(data, MIN_X, MAX_X, MIN_Y, MAX_Y):\n",
    "    \"\"\"\n",
    "    Affiche :\n",
    "      - Les hubs principaux (cercles noirs) et leurs ID\n",
    "      - Les sous‑villes de chaque hub (carrés orange) et leur ID hub.sousID\n",
    "      - La boîte périphérique de chaque hub (segments bleus/rouges)\n",
    "    data : dict {\n",
    "        hub_id: {\n",
    "            'x': float, 'y': float,\n",
    "            'periph': {'x1','x2','y1','y2'},\n",
    "            'sousVilles': {\n",
    "                sous_id: {'x','y'}, …\n",
    "            }\n",
    "        }, …\n",
    "    }\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # 1) Hubs et leurs étiquettes\n",
    "    for hub_id, attrs in data.items():\n",
    "        x, y = attrs['x'], attrs['y']\n",
    "        plt.scatter(x, y, marker='o', color='black',\n",
    "                    label='Hub' if hub_id == 0 else \"\")\n",
    "        plt.text(x, y, str(hub_id), fontsize=9, ha='right', va='bottom')\n",
    "\n",
    "    # 2) Sous‑villes pour chaque hub\n",
    "    for hub_id, attrs in data.items():\n",
    "        for sv_id, coord in attrs.get('sousVilles', {}).items():\n",
    "            x_s, y_s = coord['x'], coord['y']\n",
    "            plt.scatter(x_s, y_s, marker='s', color='orange',\n",
    "                        label='Sous‑ville' if (hub_id == 0 and sv_id == 0) else \"\")\n",
    "            plt.text(x_s, y_s, f\"{hub_id}.{sv_id}\",\n",
    "                     fontsize=7, ha='left', va='bottom')\n",
    "\n",
    "    # 3) Boîtes périphériques (x1,x2,y1,y2) pour chaque hub\n",
    "    for hub_id, attrs in data.items():\n",
    "        p = attrs['periph']\n",
    "        x1, x2 = p['x1'], p['x2']\n",
    "        y1, y2 = p['y1'], p['y2']\n",
    "        # trait bas et haut\n",
    "        plt.hlines(y1, x1, x2, colors='blue', linestyles='--', alpha=0.7)\n",
    "        plt.hlines(y2, x1, x2, colors='blue', linestyles='--', alpha=0.7)\n",
    "        # trait gauche et droite\n",
    "        plt.vlines(x1, y1, y2, colors='red', linestyles='--', alpha=0.7)\n",
    "        plt.vlines(x2, y1, y2, colors='red', linestyles='--', alpha=0.7)\n",
    "\n",
    "    # 4) Cadre et légende\n",
    "    plt.xlim(MIN_X, MAX_X)\n",
    "    plt.ylim(MIN_Y, MAX_Y)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Hubs, sous‑villes et boîtes périphériques')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_graph_data(data, figsize=(8, 8),\n",
    "                    base_hub_size=200, base_vill_size=20,\n",
    "                    size_factor=50, title='Graphe'):\n",
    "    \"\"\"\n",
    "    Affiche chaque nœud en taille proportionnelle à son degré.\n",
    "    - hubs : marker '^', taille de base base_hub_size\n",
    "    - villages : marker 'o', taille de base base_vill_size\n",
    "    - size_factor : ajout de taille par arête\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # 1) Tracer les arêtes\n",
    "    drawn = set()\n",
    "    for u, attrs in data.items():\n",
    "        x1, y1 = attrs['x'], attrs['y']\n",
    "        for v, weights in attrs['neighbours'].items():\n",
    "            if (v, u) in drawn:\n",
    "                continue\n",
    "            x2, y2 = data[v]['x'], data[v]['y']\n",
    "            ax.plot([x1, x2], [y1, y2], color='gray', alpha=0.5)\n",
    "            drawn.add((u, v))\n",
    "\n",
    "    # 2) Couleurs par cluster\n",
    "    clusters = sorted({attrs['cluster'] for attrs in data.values()})\n",
    "    cmap = plt.get_cmap('tab10', len(clusters))\n",
    "    cluster_color = {c: cmap(i) for i, c in enumerate(clusters)}\n",
    "\n",
    "    # 3) Tracer les nœuds\n",
    "    hub_plotted = False\n",
    "    vill_plotted = False\n",
    "    for node_id, attrs in data.items():\n",
    "        x, y = attrs['x'], attrs['y']\n",
    "        # degré = nombre d'arêtes\n",
    "        deg = sum(len(w_list) for w_list in attrs['neighbours'].values())\n",
    "        # détecter hub vs village\n",
    "        is_hub = (attrs['cluster'] == node_id)\n",
    "        if is_hub:\n",
    "            size = base_hub_size + size_factor * deg\n",
    "            marker = '^'\n",
    "            label = 'Hub' if not hub_plotted else None\n",
    "            hub_plotted = True\n",
    "        else:\n",
    "            size = base_vill_size + size_factor * deg\n",
    "            marker = 'o'\n",
    "            label = 'Village' if not vill_plotted else None\n",
    "            vill_plotted = True\n",
    "\n",
    "        color = cluster_color[attrs['cluster']]\n",
    "        ax.scatter(x, y, s=size, marker=marker,\n",
    "                   color=color, edgecolor='black',\n",
    "                   label=label)\n",
    "        ax.text(x, y, str(node_id), fontsize=8,\n",
    "                ha='center', va='center', color='white')\n",
    "\n",
    "    # 4) Finitions\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_sub_cities(data, nb_max_ville, surface_max):\n",
    "    \"\"\"\n",
    "    centre (center_x,center_y), rayon max max_radius,\n",
    "    n_points : nombre de points,\n",
    "    rate : paramètre de décroissance exponentielle (plus grand → plus concentré).\n",
    "    \"\"\"\n",
    "\n",
    "    rate = 1 - nb_max_ville // 100\n",
    "    all_cities = 0\n",
    "\n",
    "    for _, city in data.items():\n",
    "        min_x = city['periph']['x1']\n",
    "        max_x = city['periph']['x2']\n",
    "        min_y = city['periph']['y1']\n",
    "        max_y = city['periph']['y2']\n",
    "        center_x = city['x']\n",
    "        center_y = city['y']\n",
    "        all_cities += 1\n",
    "\n",
    "        nb_min_ville = nb_max_sub_cities_per_city // 2\n",
    "        surface = (max_x - min_x) * (max_y - min_y)\n",
    "        howBig = surface / surface_max * 100\n",
    "        nb = int(4 * howBig)\n",
    "        if nb > nb_max_ville:\n",
    "            nb_max_ville = nb_max_ville\n",
    "        n_points = random.randrange(nb_min_ville, nb_max_ville)\n",
    "\n",
    "        # Calcul des demi-axes\n",
    "        rx = max(center_x - min_x, max_x - center_x)\n",
    "        ry = max(center_y - min_y, min_y - center_y)\n",
    "\n",
    "        city.setdefault('sousVilles', {})\n",
    "\n",
    "        for i in range(n_points):\n",
    "            theta = random.uniform(0, 2 * math.pi)\n",
    "            # distance normale dans [0,∞), on tronque à 1 pour rester dans l'ellipse\n",
    "            d = random.expovariate(rate)\n",
    "            d = min(d, 1.0)\n",
    "            # projection dans l’ellipse\n",
    "            x = center_x + rx * d * math.cos(theta)\n",
    "            y = center_y + ry * d * math.sin(theta)\n",
    "\n",
    "            all_cities += 1\n",
    "            city['sousVilles'][i] = {'x': x, 'y': y}\n",
    "\n",
    "    return data, all_cities\n",
    "\n",
    "\n",
    "def generate_cities(MIN_X, MAX_X, MIN_Y, MAX_Y, nb_villes):\n",
    "    # Génération des coordonnées aléatoires\n",
    "    xs = [random.uniform(MIN_X, MAX_X) for _ in range(nb_villes)]\n",
    "    ys = [random.uniform(MIN_Y, MAX_Y) for _ in range(nb_villes)]\n",
    "\n",
    "    data = {i: {'x': xs[i], 'y': ys[i]} for i in range(nb_villes)}\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(nb_cities, nb_max_sub_cities_per_city, MIN_X, MAX_X, MIN_Y, MAX_Y, display_regions, display_graph,\n",
    "         display_console, save_json):\n",
    "    surface_max = MAX_X * MAX_Y\n",
    "\n",
    "    data = generate_cities(MIN_X, MAX_X, MIN_Y, MAX_Y, nb_cities)\n",
    "    data = define_cities_regions(data, MIN_X, MAX_X, MIN_Y, MAX_Y)\n",
    "    data, all_cities = generate_sub_cities(data, nb_max_sub_cities_per_city, surface_max)\n",
    "\n",
    "    if display_regions:\n",
    "        display(data, MIN_X, MAX_X, MIN_Y, MAX_Y)\n",
    "\n",
    "    data_final = build_logical_graph_data(data, max_village_dist=surface_max / 8)\n",
    "\n",
    "    if display_console:\n",
    "        pprint.pprint(data_final)\n",
    "\n",
    "    if save_json:\n",
    "        with open(f'urbain_network_{all_cities}_cities.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(data_final, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    if display_graph:\n",
    "        plot_graph_data(data_final, title='Graphe urbain : hubs')\n",
    "\n",
    "    return data_final\n",
    "\n",
    "def generate_graphe(nb_cities, nb_max_sub_cities_per_city, MIN_X, MAX_X, MIN_Y, MAX_Y, display_regions, display_graph,\n",
    "                  display_console, save_json):\n",
    "    return main(nb_cities, nb_max_sub_cities_per_city, MIN_X, MAX_X, MIN_Y, MAX_Y, display_regions, display_graph,\n",
    "                  display_console, save_json)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nb_cities = 10  # Nombre de hubs\n",
    "    nb_max_sub_cities_per_city = 30\n",
    "    MIN_X, MAX_X, MIN_Y, MAX_Y = 0, 10, 0, 10  #cadre\n",
    "\n",
    "    display_regions = False\n",
    "    display_graph = True\n",
    "    display_console = False\n",
    "    save_json = True\n",
    "\n",
    "    graphe = main(nb_cities, nb_max_sub_cities_per_city, MIN_X, MAX_X, MIN_Y, MAX_Y, display_regions, display_graph,\n",
    "                  display_console, save_json)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6b46885-42f0-414b-be0c-1c87be669dfd",
   "metadata": {},
   "source": [
    "## Clustering V1 (approche par dijkstra et 1 tour de kmean) pas convaincu\n",
    "import random\n",
    "\n",
    "'''\n",
    "Le but ici est à partir d'un sommet de départ(sommet random), calculer la distance entre le sommet et tout les autres sommets\n",
    "Si la distance au sommet trouvé est inférieur à la distance stockée, alors le sommet prend la nouvelle distance et prend le cluster du sommet en paramètre\n",
    "De cette manières, tous les sommets se lient au centroide le plus proche\n",
    "'''\n",
    "\n",
    "\n",
    "def dijkstraClustering(graphe, depart, cluster):\n",
    "    visite = set()\n",
    "    graphe[depart]['distance'] = 0\n",
    "    graphe[depart]['cluster'] = cluster\n",
    "    file = [(0, depart)]\n",
    "\n",
    "    while file:\n",
    "        file.sort()\n",
    "        dist_actuelle, noeud_actuel = file.pop(0)\n",
    "\n",
    "        if noeud_actuel in visite:\n",
    "            continue\n",
    "        visite.add(noeud_actuel)\n",
    "\n",
    "        for voisin, poids_liste in graphe[noeud_actuel]['neighbours'].items():\n",
    "            poids = poids_liste[0]\n",
    "            nouvelle_distance = dist_actuelle + poids\n",
    "            if nouvelle_distance < graphe[voisin]['distance']:\n",
    "                graphe[voisin]['distance'] = nouvelle_distance\n",
    "                graphe[voisin]['cluster'] = cluster\n",
    "                file.append((nouvelle_distance, voisin))\n",
    "\n",
    "\n",
    "'''\n",
    "On choisi k sommets aléatoires en s'assurant qu'ils soient distincts\n",
    "Pour chaque sommet, on lance la fonction dijkstraClustering\n",
    "'''\n",
    "\n",
    "\n",
    "def launchClustering(k, graphe):\n",
    "    random_numbers = random.sample(range(len(graphe)), k)\n",
    "    print('sommets choisi : ' + str(random_numbers))\n",
    "    index = 0\n",
    "    for i in random_numbers:\n",
    "        dijkstraClustering(graphe, i, index)\n",
    "        index += 1\n",
    "    return graphe\n",
    "\n",
    "\n",
    "'''\n",
    "fonction de debug pour voir les clusters des sommets\n",
    "'''\n",
    "\n",
    "\n",
    "def showCluster(graphe):\n",
    "    for i in graphe:\n",
    "        print(str(i) + ' -> ' + str(graphe[i]['cluster']))\n",
    "\n",
    "\n",
    "'''\n",
    "On utilise cette fonction pour calculer la somme des poids des arêtes pour chaque clusters afin de voir si il y a un équilibre entre les clusters\n",
    "'''\n",
    "\n",
    "\n",
    "def calcGraphWeight(graphe, k):\n",
    "    weightCluster = [0] * k\n",
    "    somme = 0\n",
    "    for i in graphe:\n",
    "        somme += graphe[i]['distance']\n",
    "        weightCluster[graphe[i]['cluster']] += graphe[i]['distance']\n",
    "    return somme, weightCluster\n",
    "\n",
    "\n",
    "'''\n",
    "On calcul la somme des écarts des distances moyenne par rappot au poids total / k afin de sortir un score se rapprochant de 100 si équilibré\n",
    "'''\n",
    "\n",
    "\n",
    "def calcQualityClusters(weightSum, weightClusters):\n",
    "    lenWeightClusters = len(weightClusters)\n",
    "    #print('optimal ' + str(weightSum/lenWeightClusters))\n",
    "    diffCalc = 0\n",
    "    for i in weightClusters:\n",
    "        diffCalc += abs(weightSum / lenWeightClusters - i)\n",
    "    #print('diffMoy ' + str(diffCalc/lenWeightClusters))\n",
    "    return (100 - (diffCalc / lenWeightClusters) / (weightSum / lenWeightClusters) * 100)\n",
    "\n",
    "\n",
    "'''\n",
    "Pour un nombre k de cluster donné,\n",
    "On prend k sommets aléatoire\n",
    "On lance le clustering\n",
    "On calcul la qualité de clustering, si ce n'est pas assez de bonne qualité,\n",
    "on ré-essaye avec de nouveaux sommets aléatoire, si on satisfait la qualité demandé, on termine \n",
    "'''\n",
    "\n",
    "\n",
    "def main(precisionAsk, graphe):\n",
    "    isOk = False\n",
    "    while isOk != True:\n",
    "        grapheTemp = graphe\n",
    "        k = 3\n",
    "        grapheTemp = launchClustering(k, grapheTemp)\n",
    "        weightSum, weightClusters = calcGraphWeight(grapheTemp, k)\n",
    "        quality = calcQualityClusters(weightSum, weightClusters)\n",
    "        if (quality > precisionAsk):\n",
    "            print('quality ' + str(quality))\n",
    "            isOk = True\n",
    "    return grapheTemp\n",
    "\n",
    "\n",
    "graphe2 = main(95, graphe)\n",
    "plot_graph_data(graphe2, title='Graphe urbain : hubs')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55ce2c7c-f7a6-4a06-9ce4-22f03add7fd6",
   "metadata": {},
   "source": [
    "# Clustering v2 avec KMeans\n",
    "\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "'''\n",
    "On utilise l'inertie ici (distance entre les sommets du cluster et le centroide du cluster) pour voir la qualité des clusters\n",
    "On test entre 1 et 10 clusters pour voir lequel nombre est le plus adapté\n",
    "On utilise la méthode elbow pour voir le meilleur nombre de cluster (On cherche la fracture dans le graphe)\n",
    "'''\n",
    "\n",
    "\n",
    "def calcBestNbCluster(df):\n",
    "    inertias = []\n",
    "    K = range(1, 10)\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "        kmeans.fit(df)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(K, inertias, 'bx-')\n",
    "    plt.xlabel('Nombre de clusters')\n",
    "    plt.ylabel('Inertie')\n",
    "    plt.title('Méthode du coude pour déterminer k optimal')\n",
    "    plt.show()\n",
    "\n",
    "    kneedle = KneeLocator(K, inertias, curve='convex', direction='decreasing')\n",
    "    optiK = kneedle.knee\n",
    "    print(\"Nombre optimal de clusters : \" + str(optiK))\n",
    "    return optiK\n",
    "\n",
    "\n",
    "'''\n",
    "On formate les données pour la lib KMeans\n",
    "On calcule le nombre optimal de clusters \n",
    "On lance KMeans afin d'affecter aux sommets le cluster le plus proche\n",
    "On en resort les coordonnées des différents centroides, le graphe clusterisé et le nombre de cluster\n",
    "'''\n",
    "\n",
    "\n",
    "def clusteringKMeans(graphe):\n",
    "    xList = []\n",
    "    yList = []\n",
    "    for node, data in graphe.items():\n",
    "        xList.append(data['x'])\n",
    "        yList.append(data['y'])\n",
    "    df = np.column_stack((xList, yList))\n",
    "\n",
    "    optiK = calcBestNbCluster(df)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=optiK, random_state=1)\n",
    "    kmeans.fit(df)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    for node, data in graphe.items():\n",
    "        data['cluster'] = labels[node]\n",
    "\n",
    "    return centroids, graphe, optiK\n",
    "\n",
    "\n",
    "centroids, graphe, k = clusteringKMeans(graphe)\n",
    "plot_graph_data(graphe, title='Graphe urbain : hubs')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc519e79-39b6-4e1a-a693-4c3ece903657",
   "metadata": {},
   "source": [
    "'''\n",
    "Les centroides passés en paramètres sont des coordonnées\n",
    "Le but ici est de récupérer pour chaque centroides le point le proche de chaque cluster avec la distance euclidienne\n",
    "'''\n",
    "\n",
    "\n",
    "def calcSommet(graphe, centroids):\n",
    "    centreList = [float('inf')] * len(centroids)\n",
    "    numberCentreList = [None] * len(centroids)\n",
    "\n",
    "    for node, data in graphe.items():\n",
    "        for idx, centre in enumerate(centroids):\n",
    "            dist = math.sqrt((centre[0] - data['x']) ** 2 + (centre[1] - data['y']) ** 2)\n",
    "            if dist < centreList[idx]:\n",
    "                centreList[idx] = dist\n",
    "                numberCentreList[idx] = node\n",
    "\n",
    "    return numberCentreList\n",
    "\n",
    "\n",
    "'''\n",
    "Pour un graphe donné, fait plusieurs listes des sommets de chaque cluster \n",
    "'''\n",
    "\n",
    "\n",
    "def divideGInSg(graphe, k):\n",
    "    listClusters = [[] for i in range(k)]\n",
    "    for node, data in graphe.items():\n",
    "        cluster_index = data['cluster']\n",
    "        listClusters[cluster_index].append(node)\n",
    "    return listClusters\n",
    "\n",
    "\n",
    "listGraphe = divideGInSg(graphe, k)\n",
    "\n",
    "'''\n",
    "Un dijkstra pour tenter d'acceder à tous les sommets du cluster associé au sommet de départ passé en paramètre\n",
    "Renvoie la liste des sommets accedés (les sommets connexe au cluster)\n",
    "'''\n",
    "\n",
    "\n",
    "def allConnexeSom(graphe, depart):\n",
    "    visite = []\n",
    "    file = [depart]\n",
    "    while file:\n",
    "        file.sort()\n",
    "        noeud_actuel = file.pop(0)\n",
    "        if noeud_actuel in visite:\n",
    "            continue\n",
    "        visite.append(noeud_actuel)\n",
    "        for voisin in graphe[noeud_actuel]['neighbours']:\n",
    "            if voisin not in visite and graphe[voisin]['cluster'] == graphe[depart]['cluster']:\n",
    "                file.append(voisin)\n",
    "    return visite\n",
    "\n",
    "\n",
    "'''\n",
    "Tant qu'il reste des sommets non traités\n",
    "    On prend un sommet en tant qu'actuel à l'index donné\n",
    "    On récupère les voisins du sommet actuel qui n'appartiennent pas au meême cluster\n",
    "        On récupère la distance et le cluster du voisin qu'on stocke dans le tuple à l'index du cluster\n",
    "    Après avoir traité tous les voisins on récupère les candidats (clusters ayant le plus de voisins)\n",
    "    Et si il y a égalité, on prend le cluster ayant la distance la plus petite\n",
    "    On retire le sommet de la liste et on recommence le parcours\n",
    "    Sinon aucun candidat(Tous les voisins sont du même cluster que le sommet (ça arrive si on a plein de sommets connexe entre eux mais pas connexe à leur cluster))\n",
    "        On passe à l'index (Sommet) suivant\n",
    "'''\n",
    "\n",
    "\n",
    "def associateToNewCluster(graphe, listSomIncoCluster):\n",
    "    listIncoC = [s for cluster_set in listSomIncoCluster for s in cluster_set]\n",
    "    index = 0\n",
    "    while len(listIncoC) > 0 and index < len(listIncoC):\n",
    "        sommet = listIncoC[index]\n",
    "\n",
    "        clusterStats = [(0, 0.0) for i in range(len(listSomIncoCluster))]\n",
    "\n",
    "        for voisin in graphe[sommet]['neighbours']:\n",
    "            if graphe[sommet]['cluster'] != graphe[voisin]['cluster']:\n",
    "                distance = graphe[sommet]['neighbours'][voisin]\n",
    "                voisin_cluster = graphe[voisin]['cluster']\n",
    "                nb_voisins, total_dist = clusterStats[voisin_cluster]\n",
    "                clusterStats[voisin_cluster] = (nb_voisins + 1, total_dist + min(distance))\n",
    "\n",
    "        max_voisins = max(stats[0] for stats in clusterStats)\n",
    "        candidats = [idx for idx, stats in enumerate(clusterStats) if stats[0] == max_voisins]\n",
    "\n",
    "        if len(candidats) != 0:\n",
    "            if len(candidats) == 1:\n",
    "                bestCluster = candidats[0]\n",
    "            elif len(candidats) > 1:\n",
    "                bestCluster = min(candidats, key=lambda idx: clusterStats[idx][1])\n",
    "            graphe[sommet]['cluster'] = bestCluster\n",
    "            listIncoC.pop(index)\n",
    "            index = 0\n",
    "        else:\n",
    "            index += 1\n",
    "    return graphe\n",
    "\n",
    "\n",
    "'''\n",
    "Tant que les sous graphes(clusters) ne sont pas connexe sur eux mêmes, on boucle\n",
    "On récupère les listes de sommets pour chaque clusters\n",
    "Pour chaque cluster à partir de son centre, \n",
    "    on récupère la liste des sommets connexe du cluster\n",
    "    On regarde la différence entre les sommets du cluster et les sommets accessible \n",
    "    Si il y a une différence sur au moins un cluster alors il faut réatribuer les sommets non connexex à un autre cluster (associateToNewCluster)\n",
    "'''\n",
    "\n",
    "\n",
    "def forIsConnexe(graphe, centroides, k):\n",
    "    isAllClusterConnexe = False\n",
    "    while isAllClusterConnexe == False:\n",
    "        listSomIncoCluster = [None] * k\n",
    "        listClusters = divideGInSg(graphe, k)\n",
    "        isAllClusterConnexe = True\n",
    "        for idx, centroide in enumerate(centroides):\n",
    "            listSommet = listClusters[idx]\n",
    "            connexeSom = allConnexeSom(graphe, centroide)\n",
    "            difference = set(listSommet) - set(connexeSom)\n",
    "            if len(difference) != 0:\n",
    "                isAllClusterConnexe = False\n",
    "            listSomIncoCluster[idx] = difference\n",
    "        print(listSomIncoCluster)\n",
    "        if isAllClusterConnexe == False:\n",
    "            graphe = associateToNewCluster(graphe, listSomIncoCluster)\n",
    "    return graphe\n",
    "\n",
    "\n",
    "graphe3 = forIsConnexe(graphe, calcSommet(graphe, centroids), k)\n",
    "\n",
    "plot_graph_data(graphe3, title='Graphe urbain : hubs')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Diviser le graphe en liste de sous graphes",
   "id": "8a2fb111484e3669"
  },
  {
   "cell_type": "code",
   "id": "4f119c42-71dc-4d02-8da4-138f4a944a30",
   "metadata": {},
   "source": [
    "import copy\n",
    "\n",
    "def divideGInSgDict(graphe, k):\n",
    "    listClusters = [{} for i in range(k)]\n",
    "    for node, data in graphe.items():\n",
    "        cluster_index = data['cluster']\n",
    "        # Remove neighbours that are not in the cluster\n",
    "        data_copy = copy.deepcopy(data)\n",
    "        for neighbour in data['neighbours'].keys():\n",
    "            if graphe[neighbour]['cluster'] != cluster_index:\n",
    "                del data_copy['neighbours'][neighbour]\n",
    "        (listClusters[cluster_index])[node] = data_copy\n",
    "        graphe[node] = data_copy\n",
    "    return listClusters, graphe\n",
    "\n",
    "\n",
    "grapheDivise, graphe0 = divideGInSgDict(graphe3, k)\n",
    "plot_graph_data(graphe0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rendre le graphe complet avec A*",
   "id": "396bb32b61c99490"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def heuristic(graph, a, b):\n",
    "    weights = [w[0] for w in graph[a]['neighbours'].values()]\n",
    "    return min(weights) if weights else 0\n",
    "\n",
    "\n",
    "def a_star_weighted(graph, start, goal):\n",
    "    open_set = [(0, start)]  # liste de tuples (f_score, sommet)\n",
    "    came_from = {}\n",
    "    g_score = {node: float('inf') for node in graph}\n",
    "    g_score[start] = 0\n",
    "\n",
    "    while open_set:\n",
    "        # Trie pour récupérer le noeud avec le plus petit f_score\n",
    "        open_set.sort(key=lambda x: x[0])\n",
    "        _, current = open_set.pop(0)\n",
    "\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            total_cost = g_score[goal]\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            path.reverse()\n",
    "            return path, total_cost\n",
    "\n",
    "        for neighbour, weights in graph[current]['neighbours'].items():\n",
    "            weight = weights[0]\n",
    "            tentative_g_score = g_score[current] + weight\n",
    "\n",
    "            if tentative_g_score < g_score[neighbour]:\n",
    "                came_from[neighbour] = current\n",
    "                g_score[neighbour] = tentative_g_score\n",
    "                f_score = tentative_g_score + heuristic(graph, neighbour, goal)\n",
    "\n",
    "                # Mise à jour dans open_set : on évite les doublons\n",
    "                found = False\n",
    "                for i in range(len(open_set)):\n",
    "                    if open_set[i][1] == neighbour:\n",
    "                        if f_score < open_set[i][0]:\n",
    "                            open_set[i] = (f_score, neighbour)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    open_set.append((f_score, neighbour))\n",
    "    return None, float('inf')\n",
    "\n",
    "\n",
    "def build_complete_graph(graph):\n",
    "    graph2 = copy.deepcopy(graph)\n",
    "    correspondance = {}\n",
    "    for u in graph:\n",
    "        for v in graph:\n",
    "            if u == v or v in graph[u]['neighbours']:\n",
    "                continue\n",
    "\n",
    "            path, cost = a_star_weighted(graph, u, v)\n",
    "\n",
    "            if path and cost < float('inf'):\n",
    "                correspondance[u, v] = path\n",
    "                graph2[u]['neighbours'][v] = [cost]\n",
    "                graph2[v]['neighbours'][u] = [cost]\n",
    "\n",
    "    return correspondance, graph2\n",
    "\n",
    "\n",
    "def expand_path_with_mapping(path, edge_mapping):\n",
    "    \"\"\"Étend les arêtes du chemin selon le dictionnaire edge_mapping.\"\"\"\n",
    "    expanded_path = []\n",
    "    for i in range(len(path) - 1):\n",
    "        u, v = path[i], path[i + 1]\n",
    "        if (u, v) in edge_mapping:\n",
    "            segment = edge_mapping[(u, v)]\n",
    "        elif (v, u) in edge_mapping:\n",
    "            segment = edge_mapping[(v, u)][::-1]  # inverser si chemin dans l'autre sens\n",
    "        else:\n",
    "            segment = [u, v]\n",
    "\n",
    "        if expanded_path:\n",
    "            # Évite les doublons entre segments consécutifs\n",
    "            expanded_path.extend(segment[1:])\n",
    "        else:\n",
    "            expanded_path.extend(segment)\n",
    "\n",
    "    return expanded_path"
   ],
   "id": "d5929de3a55feb43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Max Min Ant System",
   "id": "def83924749efae9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import imageio\n",
    "import io\n",
    "\n",
    "#N_ANTS = 100\n",
    "ALPHA = 1.0  # Influence de la trace de phéromone (+ -> fourmis suivent plus la trace)\n",
    "BETA = 5.0  # Influence de la visibilité (+ -> chemin le plus court)\n",
    "EVAPORATION_RATE = 0.08  # rho\n",
    "TAU_MIN = 0.01  # Phéromone minimale\n",
    "#TAU_MAX = 2.0  # Phéromone maximale\n",
    "STAGNATION_MAX = 500  # Nombre d’itérations sans amélioration avant stagnation\n",
    "\n",
    "def compute_tau_min(tau_max, n):\n",
    "    \"\"\"\n",
    "    Calcul du tax min en fonction de tau_max et du nombre de sommets n.\n",
    "    :param tau_max:\n",
    "    :param n:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    exponent = math.sqrt(0.05)\n",
    "    numerator = tau_max * (1 - n ** exponent)\n",
    "    denominator = (n ** 2 - 1) * n ** exponent\n",
    "    return numerator / denominator\n",
    "\n",
    "def nearest_neighbor_cost(graph, start):\n",
    "    \"\"\"\n",
    "    Calcule le coût du chemin le plus court en utilisant l'algorithme du voisin le plus proche.\n",
    "    :param graph:\n",
    "    :param start:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    visited = {start}\n",
    "    current = start\n",
    "    cost = 0\n",
    "\n",
    "    while len(visited) < len(graph):\n",
    "        neighbours = {\n",
    "            v: graph[current]['neighbours'][v][0]\n",
    "            for v in graph[current]['neighbours']\n",
    "            if v not in visited\n",
    "        }\n",
    "        if not neighbours:\n",
    "            break\n",
    "        next_node = min(neighbours, key=neighbours.get)\n",
    "        cost += neighbours[next_node]\n",
    "        visited.add(next_node)\n",
    "        current = next_node\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def distance(graph, a, b):\n",
    "    \"\"\"\n",
    "    Calcule la distance entre deux sommets a et b dans le graphe.\n",
    "    :param graph:\n",
    "    :param a:\n",
    "    :param b:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if b in graph[a]['neighbours']:\n",
    "        return graph[a]['neighbours'][b][0]  # On utilise le poids comme distance\n",
    "    return float('inf')\n",
    "\n",
    "\n",
    "def initialize_pheromones(graph, tau_min=TAU_MIN):\n",
    "    \"\"\"\n",
    "    Initialise les phéromones sur les arêtes du graphe.\n",
    "    :param graph:\n",
    "    :param tau_min:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pheromones = {}\n",
    "    for vertex in graph:\n",
    "        for neighbour in graph[vertex]['neighbours']:\n",
    "            pheromones[(vertex, neighbour)] = tau_min\n",
    "            pheromones[(neighbour, vertex)] = tau_min\n",
    "    return pheromones\n",
    "\n",
    "\n",
    "def transition_probability(current, neighbours, pheromones):\n",
    "    \"\"\"\n",
    "    Calcule la probabilité de transition vers les voisins en fonction des phéromones et de la visibilité (fonction heuristique).\n",
    "    :param current:\n",
    "    :param neighbours:\n",
    "    :param pheromones:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    numerators = {}\n",
    "    total = 0.0\n",
    "\n",
    "    for neighbour in neighbours:\n",
    "        weight = min(neighbours[neighbour])\n",
    "        tau = pheromones.get((current, neighbour, weight), TAU_MIN)\n",
    "        eta = 1.0 / weight  # heuristic information\n",
    "        numerators[neighbour] = (tau ** ALPHA) * (eta ** BETA)\n",
    "        total += numerators[neighbour]\n",
    "\n",
    "    if total == 0:\n",
    "        # If all probabilities are 0, distribute equally\n",
    "        return {n: 1.0 / len(neighbours) for n in neighbours}\n",
    "\n",
    "    return {n: numerators[n] / total for n in numerators}\n",
    "\n",
    "\n",
    "def next_vertex(probas):\n",
    "    \"\"\"\n",
    "    Sélectionne le prochain sommet en fonction des probabilités.\n",
    "    :param probas:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    r = random.random()\n",
    "    cumulative = 0.0\n",
    "    for vertex, prob in probas.items():\n",
    "        cumulative += prob\n",
    "        if r <= cumulative:\n",
    "            return vertex\n",
    "    return list(probas.keys())[-1]  # fallback\n",
    "\n",
    "\n",
    "def path_cost(path, graph):\n",
    "    \"\"\"\n",
    "    Calcule le coût total du chemin en utilisant les poids des arêtes.\n",
    "    :param path:\n",
    "    :param graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        u = path[i]\n",
    "        v = path[i + 1]\n",
    "        cost += min(graph[u]['neighbours'][v])\n",
    "    return cost\n",
    "\n",
    "def plot_path(graph, path, iteration, frames):\n",
    "    \"\"\"\n",
    "    Trace le chemin sur le graphe et sauvegarde l'image dans une liste de frames.\n",
    "    :param graph:\n",
    "    :param path:\n",
    "    :param iteration:\n",
    "    :param frames:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    x = [graph[node]['x'] for node in graph]\n",
    "    y = [graph[node]['y'] for node in graph]\n",
    "\n",
    "    ax.scatter(x, y, c='blue', label='Sommets')\n",
    "\n",
    "    # Tracer le chemin\n",
    "    for i in range(len(path) - 1):\n",
    "        u = path[i]\n",
    "        v = path[i + 1]\n",
    "        x_coords = [graph[u]['x'], graph[v]['x']]\n",
    "        y_coords = [graph[u]['y'], graph[v]['y']]\n",
    "        ax.plot(x_coords, y_coords, c='red')\n",
    "\n",
    "    ax.set_title(f\"Iteration {iteration}\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Sauvegarder dans une image mémoire\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = imageio.v3.imread(buf)  # Utiliser imageio.v3\n",
    "    frames.append(image)\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "\n",
    "def build_ant_solution(graph, starting_vertex, pheromones):\n",
    "    \"\"\"\n",
    "    Construit une solution de chemin en utilisant une fourmi.\n",
    "    :param graph:\n",
    "    :param starting_vertex:\n",
    "    :param pheromones:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = [starting_vertex]\n",
    "    current = starting_vertex\n",
    "    visited = set(path)\n",
    "\n",
    "    # Tant que tous les sommets ne sont pas visités\n",
    "    while len(visited) < len(graph):\n",
    "        neighbors = {\n",
    "            n: graph[current]['neighbours'][n]\n",
    "            for n in graph[current]['neighbours']\n",
    "            if n not in visited\n",
    "        }\n",
    "\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        probabilities = transition_probability(current, neighbors, pheromones)\n",
    "        next_node = next_vertex(probabilities)\n",
    "        path.append(next_node)\n",
    "        visited.add(next_node)\n",
    "        current = next_node\n",
    "\n",
    "    # Une fois tous les sommets visités, retourner au point de départ\n",
    "    if starting_vertex in graph[current]['neighbours']:\n",
    "        path.append(starting_vertex)  # retourner au départ pour fermer le cycle\n",
    "        cost = path_cost(path, graph)\n",
    "        return path, cost\n",
    "\n",
    "    if len(path) == len(graph):\n",
    "        cost = path_cost(path, graph)\n",
    "        return path, cost\n",
    "\n",
    "    return None, float('inf')\n",
    "\n",
    "\n",
    "def max_min_ant_system(graph, starting_vertex, create_gif=True, print_solution=True):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme Max Min Ant System (MMAS) pour le TSP.\n",
    "    :param graph:\n",
    "    :param starting_vertex:\n",
    "    :param create_gif:\n",
    "    :param print_solution:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pheromones = initialize_pheromones(graph)\n",
    "    best_path = None\n",
    "    best_cost = float('inf')\n",
    "    stagnation = 0\n",
    "\n",
    "    N_VERTICES = len(graph)\n",
    "    # Paramètre dynamique\n",
    "    N_ANTS = len(graph) // 2\n",
    "    C_best_nn = nearest_neighbor_cost(graph, starting_vertex)\n",
    "    TAU_MAX = float(1 / (EVAPORATION_RATE * C_best_nn))\n",
    "    TAU_MIN = float(compute_tau_min(TAU_MAX, N_VERTICES))\n",
    "\n",
    "    # For the GIF\n",
    "    frames = []\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        solutions = []\n",
    "\n",
    "        for _ in range(N_ANTS):\n",
    "            path, cost = build_ant_solution(graph, starting_vertex, pheromones)\n",
    "            if path:\n",
    "                solutions.append((path, cost))\n",
    "\n",
    "        iteration_best_path, iteration_best_cost = min(solutions, key=lambda x: x[1])\n",
    "\n",
    "        # Mise à jour de la meilleure solution\n",
    "        if iteration_best_cost < best_cost:\n",
    "            best_path = iteration_best_path\n",
    "            best_cost = iteration_best_cost\n",
    "\n",
    "            if print_solution:\n",
    "                print(\"New solution found : \", best_cost)\n",
    "            stagnation = 0\n",
    "            if create_gif:\n",
    "                plot_path(graph, best_path + [best_path[0]], iteration, frames)\n",
    "        else:\n",
    "            stagnation += 1\n",
    "\n",
    "        if stagnation >= STAGNATION_MAX:\n",
    "            break\n",
    "\n",
    "        # Évaporation\n",
    "        for edge in pheromones:\n",
    "            pheromones[edge] = max(pheromones[edge] * (1 - EVAPORATION_RATE), TAU_MIN)\n",
    "\n",
    "        # Renforcement du chemin optimal\n",
    "        delta_tau = 1.0 / best_cost\n",
    "        for i in range(len(best_path) - 1):\n",
    "            u = best_path[i]\n",
    "            v = best_path[i + 1]\n",
    "            for edge in [(u, v), (v, u)]:\n",
    "                pheromones[edge] = min(pheromones.get(edge, TAU_MIN) + delta_tau, TAU_MAX)\n",
    "\n",
    "    if create_gif:\n",
    "        cluster = next(iter(graph.values()))['cluster']\n",
    "        imageio.mimsave('evolution_mmas_' + str(cluster) + '.gif', frames, duration=5)\n",
    "        print(\"GIF enregistré sous 'evolution_mmas_\" + str(cluster) + \".gif'\")\n",
    "\n",
    "    return best_path, best_cost"
   ],
   "id": "fd952e8a3d92fb59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Max Min Ant System",
   "id": "5032e60f251fd105"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "graphe3 = {0: {'cluster': 0, 'neighbours': {1: [77]}, 'x': 0, 'y': 0},\n",
    " 1: {'cluster': 0,\n",
    "     'neighbours': {0: [77], 2: [82], 3: [19]},\n",
    "     'x': -43,\n",
    "     'y': -64},\n",
    " 2: {'cluster': 0, 'neighbours': {1: [82], 3: [64]}, 'x': -60, 'y': 17},\n",
    " 3: {'cluster': 0,\n",
    "     'neighbours': {1: [19], 4: [96], 5: [70], 6: [88]},\n",
    "     'x': -27,\n",
    "     'y': -53},\n",
    " 4: {'cluster': 0,\n",
    "     'neighbours': {3: [96], 5: [70], 6: [52], 7: [44]},\n",
    "     'x': 65,\n",
    "     'y': -83},\n",
    " 5: {'cluster': 0,\n",
    "     'neighbours': {3: [70], 6: [45], 7: [50]},\n",
    "     'x': 43,\n",
    "     'y': -43},\n",
    " 6: {'cluster': 0,\n",
    "     'neighbours': {3: [88], 7: [93], 8: [7]},\n",
    "     'x': 45,\n",
    "     'y': -104},\n",
    " 7: {'cluster': 0,\n",
    "     'neighbours': {6: [93], 8: [43], 9: [57]},\n",
    "     'x': -48,\n",
    "     'y': -91},\n",
    " 8: {'cluster': 0,\n",
    "     'neighbours': {6: [7], 9: [34], 10: [120], 11: [37]},\n",
    "     'x': 43,\n",
    "     'y': -111},\n",
    " 9: {'cluster': 0,\n",
    "     'neighbours': {8: [34], 10: [67], 11: [94]},\n",
    "     'x': 16,\n",
    "     'y': -89},\n",
    " 10: {'cluster': 0,\n",
    "      'neighbours': {8: [120], 11: [89], 12: [89]},\n",
    "      'x': -52,\n",
    "      'y': -185},\n",
    " 11: {'cluster': 0, 'neighbours': {8: [37], 12: [47]}, 'x': 65, 'y': -141},\n",
    " 12: {'cluster': 0, 'neighbours': {11: [47], 13: [67]}, 'x': 40, 'y': -181},\n",
    " 13: {'cluster': 0, 'neighbours': {12: [67], 14: [112]}, 'x': 90, 'y': -227},\n",
    " 14: {'cluster': 0,\n",
    "      'neighbours': {13: [112], 15: [62], 16: [112]},\n",
    "      'x': 31,\n",
    "      'y': -131},\n",
    " 15: {'cluster': 0, 'neighbours': {14: [62], 16: [69]}, 'x': 61, 'y': -76},\n",
    " 16:{'neighbours': {14: [112], 15: [69]}}}\n",
    "\n",
    "correspondance, newGraph = build_complete_graph(graphe3)\n",
    "#starting_vertex = random.choice(list(newGraph.keys()))\n",
    "\n",
    "time1 = time.time()\n",
    "best_path, best_cost = max_min_ant_system(newGraph, 0, False)\n",
    "time2 = time.time()\n",
    "\n",
    "expanded_path = expand_path_with_mapping(best_path, correspondance)\n",
    "print(\"Meilleur chemin :\", expanded_path)\n",
    "print(\"Coût total :\", best_cost)\n",
    "print(\"Temps d'exécution :\", time2 - time1, \"secondes\")"
   ],
   "id": "efcfb44b2d19bfb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "for subgraph in grapheDivise:\n",
    "    #plot_graph_data(subgraph)\n",
    "    correspondance, newGraph = build_complete_graph(subgraph)\n",
    "    starting_vertex = random.choice(list(newGraph.keys()))\n",
    "\n",
    "    time1 = time.time()\n",
    "    best_path, best_cost = max_min_ant_system(newGraph, starting_vertex)\n",
    "    time2 = time.time()\n",
    "\n",
    "    expanded_path = expand_path_with_mapping(best_path, correspondance)\n",
    "    print(\"Meilleur chemin :\", expanded_path)\n",
    "    print(\"Coût total :\", best_cost)\n",
    "    print(\"Temps d'exécution :\", time2 - time1, \"secondes\")"
   ],
   "id": "d98c2e107fba5e93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Étude expérimentale de l'algorithme Max-Min Ant System (MMAS)\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Évaluer le comportement expérimental de l'algorithme Max-Min Ant System (MMAS) sur des graphes de différentes tailles.\n",
    "Analyser l'impact des principaux paramètres (nombre de fourmis, taux d'évaporation, bêta) sur :\n",
    "- la qualité des solutions,\n",
    "- le temps de calcul,\n",
    "- la robustesse de la convergence.\n",
    "\n",
    "Proposer des perspectives d'amélioration à partir de ces observations."
   ],
   "id": "5311dc81cf95b696"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Plan d'Expérience\n",
    "\n",
    "Nous faisons varier :\n",
    "\n",
    "- La taille du graphe : 9, 20, 50, 100 et 300 sommets\n",
    "\n",
    "Pour chaque configuration :\n",
    "- 5 exécutions sont réalisées pour prendre en compte l'aspect stochastique de l'algorithme.\n",
    "- Nous mesurons :\n",
    "  - Le coût final du meilleur chemin\n",
    "  - Le temps d'exécution\n",
    "  - Le nombre d'itérations jusqu'à stagnation"
   ],
   "id": "7bbc07f70b3312af"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-28T11:57:42.491499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ajout de la fonction pour tracer les résultats des algorithmes\n",
    "def plot_algorithm_results(results, title=\"Comparaison des algorithmes\"):\n",
    "    \"\"\"\n",
    "    Trace les résultats des différents algorithmes sous forme de courbes.\n",
    "    :param results: Liste de dictionnaires contenant les résultats des algorithmes.\n",
    "                    Chaque dictionnaire doit avoir les clés 'algorithm', 'size', 'cost', 'time'.\n",
    "    :param title: Titre du graphique.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Taille du graphe')\n",
    "    ax1.set_ylabel('Coût moyen', color=color)\n",
    "    for algo in df['algorithm'].unique():\n",
    "        subset = df[df['algorithm'] == algo]\n",
    "        # Calculer la moyenne des coûts pour chaque taille\n",
    "        mean_cost = subset.groupby('size')['cost'].mean().reset_index()\n",
    "        ax1.plot(mean_cost['size'], mean_cost['cost'], marker='o', label=f\"{algo} (Coût)\", color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Temps moyen (s)', color=color)\n",
    "    for algo in df['algorithm'].unique():\n",
    "        subset = df[df['algorithm'] == algo]\n",
    "        # Calculer la moyenne des temps pour chaque taille\n",
    "        mean_time = subset.groupby('size')['time'].mean().reset_index()\n",
    "        ax2.plot(mean_time['size'], mean_time['time'], marker='x', label=f\"{algo} (Temps)\", color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.9))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Étude expérimentale avec comparaison des algorithmes\n",
    "sizes = [(1, 20), (2, 25), (5, 20)]  # tailles de graphe\n",
    "repeats = 5  # nombre de répétitions pour chaque taille\n",
    "\n",
    "results = []\n",
    "\n",
    "for (nb_cities, nb_subcities) in sizes:\n",
    "    print(f\"Lancement pour taille {nb_cities * nb_subcities}...\")\n",
    "\n",
    "    for iteration in range(repeats):\n",
    "        print(f\"Iteration {iteration + 1}/{repeats}\")\n",
    "        graph = generate_graphe(nb_cities, nb_subcities, 0, 10, 0, 10, False, False, False, False)\n",
    "        starting_vertex = random.choice(list(graph.keys()))\n",
    "        correspondance, complete_graph = build_complete_graph(graph)\n",
    "\n",
    "        # Max-Min Ant System\n",
    "        start_time = time.time()\n",
    "        _, best_cost_mmas = max_min_ant_system(complete_graph, starting_vertex, False, False)\n",
    "        end_time = time.time()\n",
    "        results.append({\n",
    "            'algorithm': 'MMAS',\n",
    "            'size': nb_cities * nb_subcities,\n",
    "            'cost': best_cost_mmas,\n",
    "            'time': end_time - start_time\n",
    "        })\n",
    "\n",
    "        # Ajout d'autres algorithmes ici si nécessaire\n",
    "        # Exemple :\n",
    "        # start_time = time.time()\n",
    "        # _, best_cost_other = other_algorithm(complete_graph, starting_vertex)\n",
    "        # end_time = time.time()\n",
    "        # results.append({\n",
    "        #     'algorithm': 'OtherAlgorithm',\n",
    "        #     'size': nb_cities * nb_subcities,\n",
    "        #     'cost': best_cost_other,\n",
    "        #     'time': end_time - start_time\n",
    "        # })\n",
    "\n",
    "# Tracé des résultats\n",
    "plot_algorithm_results(results, title=\"Comparaison des algorithmes\")"
   ],
   "id": "c054d07232149fed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement pour taille 20...\n",
      "Iteration 1/5\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d432a84681b189"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
